#!/bin/bash
#
# Deploy GPU Infrastructure (GPU Operator, Network Operator, KAI Scheduler)
#

set -e

SCRIPT_DIR="$(cd "$(dirname "${BASH_SOURCE[0]}")" && pwd)"
source "${SCRIPT_DIR}/lib/common.sh"
source "${SCRIPT_DIR}/defaults.conf"

echo ""
echo "========================================"
echo "  GPU Infrastructure Deployment"
echo "========================================"
echo ""

# Check prerequisites
check_kubectl || exit 1
check_helm || exit 1

# Add Helm repos
log_info "Adding Helm repositories..."
helm repo add nvidia https://helm.ngc.nvidia.com/nvidia --force-update
helm repo update

# -----------------------------------------------------------------------------
# Deploy GPU Operator
# -----------------------------------------------------------------------------
log_info "Deploying NVIDIA GPU Operator..."

kubectl create namespace "${GPU_OPERATOR_NAMESPACE}" --dry-run=client -o yaml | kubectl apply -f -

helm upgrade --install gpu-operator nvidia/gpu-operator \
    --namespace "${GPU_OPERATOR_NAMESPACE}" \
    --values "${VALUES_DIR}/gpu-operator.yaml" \
    --wait --timeout 15m

log_success "GPU Operator deployed"

# Wait for GPU Operator pods
wait_for_pods "${GPU_OPERATOR_NAMESPACE}" "app=gpu-operator" 300

# -----------------------------------------------------------------------------
# Deploy Network Operator (for InfiniBand) - OPTIONAL
# -----------------------------------------------------------------------------
if [[ "${ENABLE_NETWORK_OPERATOR:-false}" == "true" ]]; then
    log_info "Deploying NVIDIA Network Operator (InfiniBand support)..."

    kubectl create namespace "${NETWORK_OPERATOR_NAMESPACE}" --dry-run=client -o yaml | kubectl apply -f -

    helm upgrade --install network-operator nvidia/network-operator \
        --namespace "${NETWORK_OPERATOR_NAMESPACE}" \
        --values "${VALUES_DIR}/network-operator.yaml" \
        --wait --timeout 10m

    log_success "Network Operator deployed"
else
    log_info "Skipping Network Operator (set ENABLE_NETWORK_OPERATOR=true to install)"
fi

# -----------------------------------------------------------------------------
# Deploy KAI Scheduler (from NVIDIA OCI registry)
# https://nvidia.github.io/OSMO/main/deployment_guide/install_backend/dependencies/dependencies.html
# -----------------------------------------------------------------------------
log_info "Deploying KAI Scheduler..."

kubectl create namespace "${KAI_SCHEDULER_NAMESPACE}" --dry-run=client -o yaml | kubectl apply -f -

# Install directly from OCI registry
KAI_VERSION="${KAI_SCHEDULER_VERSION:-0.4.0}"
helm upgrade --install kai-scheduler \
    oci://ghcr.io/nvidia/kai-scheduler/kai-scheduler \
    --version "${KAI_VERSION}" \
    --namespace "${KAI_SCHEDULER_NAMESPACE}" \
    --values "${VALUES_DIR}/kai-scheduler.yaml" \
    --wait --timeout 5m

log_success "KAI Scheduler deployed"

# -----------------------------------------------------------------------------
# Verify Installation
# -----------------------------------------------------------------------------
echo ""
log_info "Verifying GPU infrastructure..."

# Check GPU nodes
GPU_NODES=$(kubectl get nodes -l node-type=gpu -o name 2>/dev/null | wc -l)
if [[ $GPU_NODES -gt 0 ]]; then
    log_success "Found $GPU_NODES GPU node(s)"
    kubectl get nodes -l node-type=gpu -o wide
else
    log_warning "No GPU nodes found yet (they may still be provisioning)"
fi

echo ""
echo "========================================"
log_success "GPU Infrastructure deployment complete!"
echo "========================================"
echo ""
echo "Next step: ./02-deploy-observability.sh"
echo ""
